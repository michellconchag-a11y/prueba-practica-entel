# Data Scientist Challenge ‚Äì Entel

Este repositorio contiene la resoluci√≥n de la prueba pr√°ctica

## üìÇ Estructura
- `data/` ‚Üí dataset entregado
- `scripts/` ‚Üí scripts reproducibles (part1_fill_answers.py`, `part2_train_model_xgb.py`)
- `outputs/` ‚Üí m√©tricas, gr√°ficos y predicciones generada
- `respuestas.txt` ‚Üí respuestas a las preguntas 1 a 4 de la primera parte
- `README.md` ‚Üí este archiov

## Flujo de trabajo
1. **Parte 1 (EDA):** limpieza, an√°lisis exploratorio y respuesta a preguntas descriptivas.
2. **Parte 2 (Modelado):**
   - Divisi√≥n temporal: **train = junio**, **validaci√≥n = julio**, **test = agosto**.
   - Modelos entrenados: **Logistic Regression, Random Forest, XGBoost**.
   - Selecci√≥n del mejor modelo por **PR AUC en validaci√≥n**.

## Resultados Primera Parte
### Pregunta 4 b.
Considerar√≠a eliminar aquellas columnas con muy baja variabilidad (constantes), variables altamente correlacionadas con otras que aporten la misma informaci√≥n y columnas redundantes. Esto permitir√≠a reducir dimensionalidad, simplificar el an√°lisis y evitar problemas de multicolinealidad en los modelos.

### Pregunta 5.
S√≠, existen diferencias en la distribuci√≥n. En general, los clientes que se dan de baja tienden a recargar menos veces, y su distribuci√≥n est√° m√°s concentrada en valores bajos. En cambio, los clientes que no se dan de baja presentan una mayor dispersi√≥n, incluyendo casos de muchas recargas, lo que podr√≠a implicar que la frecuencia de recargas est√° asociada a la probabilidad de permanecer en la compa√±√≠a.

## Resultados Segunda Parte
### Validaci√≥n (julio)
| Modelo              | ROC AUC | PR AUC | F1   | Precisi√≥n | Recall |
|---------------------|---------|--------|------|-----------|--------|
| Logistic Regression | 0.77    | 0.11   | 0.27 | 0.23      | 0.32   |
| Random Forest       | 0.75    | 0.13   | 0.30 | 0.24      | 0.39   |
| XGBoost             | 0.80    | 0.17   | 0.34 | 0.27      | 0.46   |

### Test (agosto)
| Modelo elegido | ROC AUC | PR AUC | F1   | Precisi√≥n | Recall |
|----------------|---------|--------|------|-----------|--------|
| XGBoost        | 0.81    | 0.24   | 0.38 | 0.29      | 0.57   |

El modelo final elegido fue **XGBoost**, con mejor PR AUC y mayor recall, detectando m√°s de la mitad de los clientes que efectivamente se dieron de baja.

## a. M√©tricas utilizadas
Dado que la clase churn es minoritaria, m√©tricas como accuracy o ROC AUC pueden resultar optimistas y no reflejar la calidad en la clase positiva. Por lo mismo, se priorizaron m√©tricas sensibles a la clase minoritaria y a la toma de decisiones operativas.

- **ROC AUC**: discriminaci√≥n global (ya se sabe que no puede ser la m√©trica primaria ya que puede ser enga√±oso en datos desbalanceados).
- **PR AUC (Average Precision)**: m√©trica clave, enfocada en la clase minoritaria.
- **F1 Score, Precisi√≥n, Recall**: ayudan a balancear y entender los trade-offs.

## b. Posibles mejoras
- **Ingenier√≠a de features**: variaciones mensuales, ratios, flags de ca√≠das bruscas.
- **Modelado**: tuning de hiperpar√°metros, probar LightGBM/CatBoost.
- **Umbral**: ajustar seg√∫n criterios de negocio (ej. recall m√≠nimo).
- **Desbalance**: t√©cnicas de oversampling/undersampling, ajuste fino de `scale_pos_weight`.

## c. Por qu√© estos modelos
El objetivo es construir un sistema que, mirando los datos pasados de un cliente (cu√°nto recarga, cu√°nto gasta, qu√© tanto usa el servicio, etc.), pueda predecir la categor√≠a en la que probablemente caer√° en el futuro (problema de clasificaci√≥n).

- **Regresi√≥n Log√≠stica:** Modelo lineal, r√°pido e interpretable. Se us√≥ como baseline para establecer un punto de comparaci√≥n inicial.
- **Random Forest:** Ensamble de m√∫ltiples √°rboles de decisi√≥n entrenados con bagging. Captura relaciones no lineales y es m√°s robusto que la regresi√≥n log√≠stica, pero puede requerir muchos √°rboles para alcanzar su mejor desempe√±o.
- **XGBoost:** Algoritmo de boosting que entrena √°rboles de forma secuencial corrigiendo errores previos. Es uno de los modelos m√°s utilizados en problemas de churn por su capacidad de manejar desbalance y explotar interacciones complejas entre variables.

**XGBoost** result√≥ ser el modelo m√°s adecuado para este dataset:
- En validaci√≥n, XGBoost fue el modelo con mayor PR AUC (0.17), mostrando mejor balance en la identificaci√≥n de bajas.
- En test, XGBoost alcanz√≥ un ROC AUC de 0.81, un PR AUC de 0.24 (el doble que la Regresi√≥n Log√≠stica en validaci√≥n) y un recall del 57%, logrando identificar a m√°s de la mitad de los clientes que efectivamente se dieron de baja.
- Se observa que en los gr√°ficos valid_xgboost_pr.png y valid_xgboost_roc.png XGBoost domina sobre los otros modelos en las curvas de precisi√≥n-recall y ROC.
